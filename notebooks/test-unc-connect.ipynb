{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of Argentina is Buenos Aires.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Your API key for the Ollama server\n",
    "API_KEY = os.environ[\"OLLAMA_API_KEY\"]\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "client_kwargs = {\"headers\": headers}\n",
    "\n",
    "# Create the Ollama chat model with custom headers for API key authorization\n",
    "chat = ChatOllama(\n",
    "    model=\"llama3.3:70b\",  # replace with the actual model name if different\n",
    "    base_url=\"https://ollama.ccad.unc.edu.ar/ollama\",\n",
    "    client_kwargs=client_kwargs,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Send a message to the model\n",
    "response = chat.invoke([\n",
    "    HumanMessage(content=\"What is the capital of Argentina?\")\n",
    "])\n",
    "\n",
    "print(\"Response:\", response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RWJsIfvPoD9S"
   },
   "outputs": [],
   "source": [
    "# import getpass\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "\n",
    "# if \"LANGSMITH_API_KEY\" not in os.environ:     #connexion au compte LangSmith pour la vérification/test/... du LLM\n",
    "#     os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "#         prompt=\"Enter your LangSmith API key (optional): \"\n",
    "#     )\n",
    "# if \"LANGSMITH_PROJECT\" not in os.environ:    #entrer le nom du projet\n",
    "#     os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "#         prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "#     )\n",
    "#     if not os.getenv('KUCOIN_API_KEY')(\"LANGSMITH_PROJECT\"):\n",
    "        \n",
    "#         os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
    "\n",
    "ollama_api_key = os.environ[\"OLLAMA_API_KEY\"]\n",
    "# print(ollama_api_key)\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "heders = headers = {\n",
    "'Authorization': f\"Bearer {ollama_api_key}\"\n",
    "}\n",
    "\n",
    "model = init_chat_model(\"llama3.3:70b\", model_provider=\"ollama\", base_url=\"https://ollama.ccad.unc.edu.ar/ollama\", client_kwargs={'headers': headers})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfbA2cYyoofP",
    "outputId": "2913d722-9804-4274-de4b-11858b56cae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args=('POST', '/api/chat')\n",
      "kwargs={'json': {'model': 'llama3.3:70b', 'stream': True, 'options': {}, 'messages': [{'role': 'user', 'content': 'Hello, world!'}], 'tools': []}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's great to see you're excited to be here. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.3:70b', 'created_at': '2025-06-10T17:55:05.887177437Z', 'done': True, 'done_reason': 'stop', 'total_duration': 60485280190, 'load_duration': 3148765819, 'prompt_eval_count': 14, 'prompt_eval_duration': 901167543, 'eval_count': 30, 'eval_duration': 56433714934, 'model_name': 'llama3.3:70b'}, id='run--7e18edcc-0be7-4cbb-b798-9a3849ff814a-0', usage_metadata={'input_tokens': 14, 'output_tokens': 30, 'total_tokens': 44})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello, world!\") #affiche \"l'objet complet\" renvoyé par le LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with debug output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2025-06-10 18:33:16] httpx - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG [2025-06-10 18:33:16] httpx - load_verify_locations cafile='/opt/conda/lib/python3.11/site-packages/certifi/cacert.pem'\n",
      "DEBUG [2025-06-10 18:33:16] httpx - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG [2025-06-10 18:33:16] httpx - load_verify_locations cafile='/opt/conda/lib/python3.11/site-packages/certifi/cacert.pem'\n",
      "DEBUG [2025-06-10 18:33:16] httpcore.connection - connect_tcp.started host='ollama.ccad.unc.edu.ar' port=443 local_address=None timeout=None socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the capital of Argentina?\"\n",
      "  ]\n",
      "}\n",
      "args=('POST', '/api/chat')\n",
      "kwargs={'json': {'model': 'llama3.3:70b', 'stream': True, 'options': {}, 'messages': [{'role': 'user', 'content': 'What is the capital of Argentina?'}], 'tools': []}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2025-06-10 18:33:21] httpcore.connection - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd995de0650>\n",
      "DEBUG [2025-06-10 18:33:21] httpcore.connection - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd9ac783380> server_hostname='ollama.ccad.unc.edu.ar' timeout=None\n",
      "DEBUG [2025-06-10 18:33:21] httpcore.connection - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd9ac640c50>\n",
      "DEBUG [2025-06-10 18:33:21] httpcore.http11 - send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG [2025-06-10 18:33:21] httpcore.http11 - send_request_headers.complete\n",
      "DEBUG [2025-06-10 18:33:21] httpcore.http11 - send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG [2025-06-10 18:33:21] httpcore.http11 - send_request_body.complete\n",
      "DEBUG [2025-06-10 18:33:21] httpcore.http11 - receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG [2025-06-10 18:33:26] httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Alt-Svc', b'h3=\":443\"; ma=2592000'), (b'Content-Type', b'application/x-ndjson'), (b'Date', b'Tue, 10 Jun 2025 18:33:20 GMT'), (b'Date', b'Tue, 10 Jun 2025 18:33:26 GMT'), (b'Server', b'Caddy'), (b'Server', b'uvicorn'), (b'X-Process-Time', b'5'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO [2025-06-10 18:33:26] httpx - HTTP Request: POST https://ollama.ccad.unc.edu.ar/ollama/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG [2025-06-10 18:33:26] httpcore.http11 - receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG [2025-06-10 18:33:42] httpcore.http11 - receive_response_body.complete\n",
      "DEBUG [2025-06-10 18:33:42] httpcore.http11 - response_closed.started\n",
      "DEBUG [2025-06-10 18:33:42] httpcore.http11 - response_closed.complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOllama] [25.62s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.3:70b\",\n",
      "          \"created_at\": \"2025-06-10T18:33:41.824863937Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 20499751963,\n",
      "          \"load_duration\": 3152933291,\n",
      "          \"prompt_eval_count\": 17,\n",
      "          \"prompt_eval_duration\": 1850370856,\n",
      "          \"eval_count\": 9,\n",
      "          \"eval_duration\": 15494879792,\n",
      "          \"model_name\": \"llama3.3:70b\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The capital of Argentina is Buenos Aires.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.3:70b\",\n",
      "              \"created_at\": \"2025-06-10T18:33:41.824863937Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 20499751963,\n",
      "              \"load_duration\": 3152933291,\n",
      "              \"prompt_eval_count\": 17,\n",
      "              \"prompt_eval_duration\": 1850370856,\n",
      "              \"eval_count\": 9,\n",
      "              \"eval_duration\": 15494879792,\n",
      "              \"model_name\": \"llama3.3:70b\"\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--9bf7c655-d68f-4f7e-b738-ecb852562c37-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 17,\n",
      "              \"output_tokens\": 9,\n",
      "              \"total_tokens\": 26\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        },\n",
      "        \"text\": \"The capital of Argentina is Buenos Aires.\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "Response: The capital of Argentina is Buenos Aires.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import httpx\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s [%(asctime)s] %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.DEBUG\n",
    ")\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.globals import set_verbose\n",
    "from langchain.globals import set_debug\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "set_debug(True)\n",
    "set_verbose(True)\n",
    "\n",
    "# Your API key for the Ollama server\n",
    "API_KEY = os.environ[\"OLLAMA_API_KEY\"]\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "client_kwargs = {\"headers\": headers}\n",
    "\n",
    "#print(API_KEY)\n",
    "# Create the Ollama chat model with custom headers for API key authorization\n",
    "chat = ChatOllama(\n",
    "    model=\"llama3.3:70b\",  # replace with the actual model name if different\n",
    "    base_url=\"https://ollama.ccad.unc.edu.ar/ollama\",\n",
    "    headers=headers,\n",
    "    client_kwargs=client_kwargs,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Send a message to the model\n",
    "response = chat.invoke([\n",
    "    HumanMessage(content=\"What is the capital of Argentina?\")\n",
    "])\n",
    "\n",
    "print(\"Response:\", response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command line to run UNC WebUI\n",
    "\n",
    "```sh\n",
    "curl -X POST https://ollama.ccad.unc.edu.ar/api/chat/completions \\\n",
    "-H \"Authorization: Bearer <API_KEY>\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "      \"model\": \"llama3.3:70b\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"Why is the sky blue?\"\n",
    "        }\n",
    "      ]\n",
    "    }'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
